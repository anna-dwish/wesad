---
title: "Stress Detection in Wearables"
author: "Alice Liao, Anna Darwish, Bernardo Martinez"
date: "9/19/2020"
output: 
  pdf_document:
     latex_engine: xelatex
     number_sections: true
---

```{r, Function checking for installed packages, echo=FALSE, results="hide", include=FALSE}
# Validate that all necessary packaged have been downloaded, install otherwise or throw err package DNE
pkgTest <- function(x)
{
  if (!require(x,character.only = TRUE))
  {
    install.packages(x,repos = "http://cran.r-project.org", dep=TRUE)
    if(!require(x,character.only = TRUE)) stop("Package not found")
  }
}
```

```{r Package Test Libraries, echo=FALSE, results="hide", include=FALSE}
pkgTest("arm")
pkgTest("broom")
pkgTest("cowplot")
pkgTest("dplyr")
pkgTest("ggplot2")
pkgTest("knitr")
pkgTest("kableExtra")
pkgTest("MASS")
pkgTest("msm")
pkgTest("plotROC")
pkgTest("pROC")
pkgTest("tidyr")
pkgTest("sjPlot")
pkgTest("sjmisc")
pkgTest("sjlabelled")
pkgTest("pander")
```

```{r Load in Libraries, echo=FALSE, results="hide", include=FALSE}
library(arm)
library(broom)
library(cowplot)
library(dplyr)
library(ggplot2)
library(knitr)
library(kableExtra)
library(MASS)
library(msm)
library(plotROC)
library(pROC)
library(tidyr)
library(sjPlot)
library(sjmisc)
library(sjlabelled)
library(pander)
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE)
ggplot2::theme_set(new = theme_bw())
```

```{r Load data, include=F}
wesad <- read.csv("merged_wesad_data.csv")

wesad <- wesad %>%
  mutate(label = as.factor(label),
         subject = as.factor(subject))
```

# Introduction

In the past few years, the use of wearables has exploded [[1]][Bibliography]. With it, researchers around the globe are exploring how tracking health information via wearables, such as a person's heart rate, can help gain insight into their physical and emotional states [[2]][Bibliography]. Across many different functionalities, such as tracking workouts or monitoring sleep, wearables also present an exciting opportunity to detect stress. In doing so, wearable users today, such as Apple watch user Jason Hiner, have become more cognizant of their emotional state and worked to improve it [[3]][Bibliography]. Given that stress can lead to long term health issues, such as heart disease, high blood pressure, diabetes, and depression or anxiety [[4]][Bibliography], it is critical for us to ensure that wearables can accurately detect stress and distinguish it from other affective states.

However, researchers have found evidence to be skeptical of the accuracy and insights a wearable watch is capable of offering [[5]][Bibliography]. For example, experts at the Cleveland Clinic found that heart-rate data in many popular wearables can be wrong 10-20% of the time [[6]][Bibliography]. While research has been done to examine whether these sensors are capable of detecting excited affective states, such as stress, relative to a subject's baseline state, there are far fewer studies that examine whether these sensors are capable of distinguishing excited affective states from one another, such as stress vs amusement [[7]][Bibliography]. A recent paper by Schmidt et. al was able to generate highly accurate machine learning models that classified wearers' states among baseline, stress, and amusement conditions using an Empatica 4 wristband [[7]][Bibliography]. However, these methods were unable to provide significant insight into the relationship between the most informative metrics and these affective states.

In this paper we hope to expand upon the work done within the Schmidt et. al paper by delving deeper into the relationship between the metrics collected by these sensors and the wearers' affective states with a logistic regression model. Specifically, we hope to accomplish the following goals:

1. Determine whether sensor data are useful in discriminating between stress and amusement conditions
2. Understand and describe how sensor data are useful in discriminating between stress and amusement
3. Determine which types and combination(s) of sensor data are most useful in discriminating between stress and amusement
4. Determine whether we can detect stress (vs amusement) only using the wrist-worn wearable
5. Quantify the heterogeneity across individuals in the response to stress versus amusement

# Data

## Collection Overview

For the purposes of this paper, we will use the biological definition of stress: an affective state defined to be the 'nonspecific response of the body to any demand upon it' [[7][Bibliography]. The data used in this paper was collected by attaching a *RespiBAN Professional* chest device and *Empatica E4* wristband to 17 graduate students. Due to sensor malfunctions, two of the subjects' data had to be discarded, for a final total of 15 subjects. Three of these subjects were women while the rest were men, and their ages ranged from 25 years old to 35 years old. This experiment sought to elicit three different affective states: neutral, stress, and amusement, and accomplished this by having the subjects perform stressful tasks (e.g public speaking) and amusing tasks (e.g watching funny videos) with breaks of meditation between sessions to restore subjects to their baseline. The stress-condition tasks and amusement-condition tasks were interchanged to avoid effects of order [[7]][Bibliography].

In the Appendix, you can see a full data dictionary in Table 1 that defines the metrics, their sampling rates, and any extracted features. Finally, it is important to note that for Subject 3, there appears to have been a brief malfunction (over a span of approximately 0.1 seconds during stressed condition) that led to impossible measurements, such as temperatures of -273$^\circ$ C. We chose to treat these ranges as missing values and also used linear interpolation to replace these faulty measurements.

## Exploratory Data Analysis

We plotted the distributions of predictors for each of the subjects and realized for some people, certain metrics serve as perfect separators for amused vs. stressed conditions (i.e. the distributions under the two conditions are significantly different or separated), but that's not always the case. Among all predictors, electrodermal activity (EDA) and temperature are the two physiological signals that appear to be separators for most of the subjects. 

```{r loadEDAgraphs, fig.width=10, fig.height=4, message=F, echo=F}
# distribution of average body temperature measured at chest (window = 60s, shift = 0.25s)
ggplot(wesad) +
  geom_histogram(aes(x=Temp_CHEST_MEAN, fill=label),alpha = 0.6, position = "identity")+
  facet_wrap(~subject, nrow = 3, scales = "free")+
  labs(x = "Body Temperature (??C)",
       title = "Figure 1: RespiBan Average Skin Temperature (Over Windows of 60 Seconds)") 
# distribution of average electrodermal activity measured at wrist (window = 60s, shift = 0.25s)
ggplot(wesad) +
  geom_histogram(aes(x=EDA_CHEST_MEAN, fill=label),alpha = 0.6, position = "identity")+
  facet_wrap(~subject, nrow = 3, scales = "free")+
  labs(x = expression(paste("Electrodermal Activity (",mu,"S)")),
       title = "Figure 2: RespiBan Average Electrodermal Activity (Over Windows of 60 Seconds)")
```

From Figure 1 we see body temperatures are different in amused vs stressed states. For some subjects, such as Subject 10 and 11, the difference is more pronounced in that the distributions of body temperatures are completely separated by the two states. Similarly in Figure 2 we observe different electrodermal acitivities in different emotional states. The histograms also suggest not everyone reacts to amusement and stress in the same way. In general, it seems more sweat (higher EDA) is associated with stress, but Subject 14 could have high EDA but was amaused too. As for temperature, some subjects had higher temperature under stress (e.g. Subject 10 and Subject 15) whereas some had lower temperature when amused (e.g. Subject 11 and Subject 17). Skin temperature and EDA measured at wrist appear to be separators too and their distributions can be found in Appendix.  

# Methods

Our first step with this dataset involved aligning the *RespiBAN* data and *Empatica E4* data. For the *RespiBAN* data, each metric was collected at 700Hz. Across all metrics, 700Hz was well above the minimum sampling rate [[8]][Bibliography], [[9]][Bibliography], [[10]][Bibliography], [[11]][Bibliography], which is defined to be the minimum number of samples needed to glean precise feature extractions. For more detail on the minimum sampling rates (MSRs) across the different metrics, please reference Table 1 in the Appendix. Despite these different MSRs, these metrics ultimately needed to be aligned to represent distinct and whole samples. We selected to downsample to 4 Hz, which has been documented as the minimum sampling rate of electrodermal activity (EDA). From our data exploration, EDA appeared to be a key metric in distinguishing stress and amusement. While there is controversy on whether higher sampling rates are required for electrodermal activity [[!!!! FIND REF !!!]], our exploratory data analysis showed that there were stark differences in the electrodermal activity between the two states for many of the subjects. We also chose this value, as temperature, which has an MSR of 1 Hz, also appeared to be a critical indicator. 

We accomplished this downsampling by calculating our features over a window of one minute with a shift of 0.25 seconds. This was motivated by the Schmidt et. al's paper's window and shift decisions. Please refer to Table 1 in the Appendix for more details on the other metrics we chose to explore, along with their transformations, throughout generating our models. (REMOVE IF ULTIMATELY FALSE) Please reference Table ** later on to compare the results of our final models to those with a sampling rate of 2 Hz for sensitivity analysis, which we accomplished with a 60 second window and 0.5 second shift.

For this paper, we have decided to generate several logistic regression models to better understand and interpret the relationship between these metrics. We began by exploring histograms and scatterplots of our metrics. From this we started with a model with the following predictors: RespiBAN EDA, RespiBAN Body Temperature, and Subject. We need to include Subject to ensure independence among our samples, as the observations within the same subject were highly correlated. We used confusion matrices, ROC curves, and binned residual plots to evaluate our model assumptions. Finally, we ran 10-fold cross-validation on each predictive model to estimate the test error. 

When we were exploring models for the wrist data, we had to take a slightly different approach. We intially began with the mean EDA as a predictor, as it perfectly separated the stress and amused condition for many of the subjects (see plot INSERT HERE DONT FORGET in the Appendix). However, this caused significant model instability and severely inflated our standard errors. For that reason, we explored other statistical features of the raw EDA signal from the wristband and noticed that the standard deviation of the raw signal also performed quite well. For subjects, such as subjects 2 and 15, that did not have as strong of separation when only using the standard deviation of EDA, we noticed the mean wrist temperature served as a useful metric.

# Results

## Chest & Wrist Model

```{r Generate and Test Wrist and Chest Model, warning=F, echo=F}
wesad$label <- as.factor(wesad$label)
wesad <- within(wesad, subject <- relevel(subject, ref = "S2"))

model.chest.final <- glm(label ~ EDA_CHEST_MEAN + Temp_CHEST_MEAN + subject, data = wesad, family = binomial)
pander(model.chest.final, caption = "Table 1")
```

$$
log(\frac{P_i(Stress)}{1 - P_i(Stress)}) = \beta_0 +  \beta_1\overline{EDA_i}^{RB} + \beta_2\overline{TEMP_i}^{RB} + \Sigma_{j \in S}\beta_{j}I(Subject = Subject_j) \\
S = \{3,4,...,11,13,...17\}
$$

Note that the $RB$ superscipt indicates that these measures came from the RespiBAN, and the baseline subject for comparison was Subject 2.

For every 0.1 $\mu s$ increase in EDA from the RespiBAN, we expect that the odds that the subject is stressed multiplies by a factor of `r round(exp(.757090),3)`. For every 0.01 degree Celsius increase in body temperature, we predict that the likelihood the subject is stressed decreases by a factor of `r round(exp(-3.37990 * 0.01),3)`. We will not be interpreting the subject coefficients as they were included in the model for independence purposes.

This model also provided statistically significant values for all the coefficients used. 

```{r Chest Model Diagnostics, echo=F}
threshold <- 0.5
model.chest.final <- augment(model.chest.final, type.predict = "response")

model.chest.final %>%
  mutate(stressed_predict = if_else(.fitted > threshold, "Stressed", "Amused")) %>%
  group_by(label, stressed_predict) %>%
  summarise(n = n()) %>%
  spread(label, n) %>%
  kable(format="markdown")

# ROC curve
ggplot(model.chest.final, aes(d = as.numeric(label), m = .fitted)) + 
  geom_roc(n.cuts = 0) + 
  geom_abline(intercept = 0)

# AUC
roc(model.chest.final$label,model.chest.final$.fitted)$auc

# Binned Residual Plots
arm::binnedplot(x=model.chest.final$.fitted,y=model.chest.final$.resid,
                xlab="Predicted Probabilities", 
                main = "Binned Residual vs. Predicted Probabilities")

```

From the confusion matrix, we can see that we are slightly more likely to produce a false positive with this model, i.e. classifying someone as stressed when they are amused. This is likely due to the fact that we have about 1.8 times as many stress-condition samples than amuse-condition samples.

From the ROC curve, we achieved an AOC of approximately 0.96, which indicates that our model has a relatively high accuracy for predicting the response. 

For the binned residuals vs predicted probabilities, we see that there appears to be a strong cubic curve. While this may suggest that we should take our predictors to a higher power, we could find any literature to motivate such a decision. Instead, we believe there are external factors that these metrics could not capture in this model. When examining the binned residuals against the mean EDA, we see that beyond 9 $\mu s$, the residuals go to 0. This is likely due to the perfect separation we saw in our data exploration. Before this, the scatter appears to be random about the 0 line. Finally, the binned residuals against body temperature show that we are generally incurring false negatives on the extreme ends of body temperature and incurring false positives between 33$^\circ$C and 35$^\circ$C (FIX INTERP)

After performing 10-fold cross validation, the average accuracy rate on the test sets was 0.894 with the worst accuracy rate being 0.889 and the best accuracy rate being 0.899. In contrast, if we had naively predicted the most frequent class in the test set, our mean accuracy rate was 0.641 with the worst accuracy rate being 0.634 and the best accuracy rate being 0.648.

```{r Generate Wrist Model, warning=F, echo=F}
model.wrist.final <- glm(label ~ EDA_EMP4_STDDEV + TEMP_EMP4_MEAN + subject, data = wesad, family = binomial)
pander(model.wrist.final, caption = "Table 2")
```

$$
log(\frac{P_i(Stress)}{1 - P_i(Stress)}) = \beta_0 +  \beta_1 * SD(EDA_i)^{E4} + \beta_2*\overline{TEMP_i}^{E4} + \Sigma_{j \in S}\beta_{j}*I(Subject = Subject_j) \\
S = \{3,4,...,11,13,...17\}
$$

Note that the $E4$ superscipt indicates that these measures came from the *Empatica E4* wristband, and we have kept the same baseline with Subject 2. 

For every 0.1 $\mu s$ increase in standard deviation of the EDA from the *Empatica E4*, we expect that the odds that the subject is stressed multiplies by a factor of `r round(exp(3.106743),3)`. For every 0.01 degree Celsius increase in skin temperature, we predict that the likelihood the subject is stressed decreases by a factor of `r round(exp(0.06455 * 0.01),3)`. Again, we will not be interpreting the subject coefficients per the aforementioned reason.

```{r  Wrist Model Diagnostics, echo=F, message=F, fig.height=5, fig.width=5}
threshold <- 0.5
model.wrist.final <- augment(model.wrist.final, type.predict = "response",type.residuals =  "pearson")

model.wrist.final %>%
  mutate(stressed_predict = if_else(.fitted > threshold, "Stressed", "Amused")) %>%
  group_by(label, stressed_predict) %>%
  summarise(n = n()) %>%
  spread(label, n) %>%
  kable(format="markdown")

roc(model.wrist.final$label,model.wrist.final$.fitted)$auc

ggplot(model.wrist.final, aes(d = as.numeric(label), m = .fitted)) + 
  geom_roc(n.cuts = 0) + 
  geom_abline(intercept = 0)

roc(model.wrist.final$label,model.wrist.final$.fitted)$auc

arm::binnedplot(x=model.wrist.final$.fitted,y=model.wrist.final$.resid,
                xlab="Predicted Probabilities", 
                main = "Binned Residual vs. Predicted Probabilities")

arm::binnedplot(x=model.wrist.final$EDA_EMP4_STDDEV,y=model.wrist.final$.resid,
                xlab="Standard Deviation of Electrodermal Activity", 
                main = "Binned Residual vs. EMP4 Electrodermal Activity")

arm::binnedplot(x=model.wrist.final$TEMP_EMP4_MEAN,y=model.wrist.final$.resid,
                xlab="Mean Skin Temperature", 
                main = "Binned Residual vs. EMP4 Skin Temperature")
```

From the confusion matrix, we are again slightly more likely to produce a false positive with this model.

From the ROC curve, we achieved an AOC of approximately 0.9273, which indicates that our model has a relatively high accuracy for predicting the response. 

For the binned residuals vs predicted probabilities, we see that there appears to be another strong cubic curve. Again, while this may suggest that we should take our predictors to a higher power, we could find any literature to motivate such a decision among the predictors in this model. Instead, we believe there are external factors that these metrics could not capture in this model. When examining the binned residuals against the standard deviation of the EDA, we see another strong curve along with significantly low residuals. The reason for this may be due to convergence issues that resulted from perfect separation for some of the subjects. Finally, the binned residuals against skin temperature show a generally random scatter, excluding a brief interval between 31$^\circ$C  and 32$^\circ$C. Additionally, we also have a few significantly large residuals towards 35$^\circ$C.

After performing 10-fold cross validation on our final wrist-only model, the average accuracy rate on the test sets was: 0.852 with the worst accuracy rate being 0.843 and the best accuracy rate being 0.858. In contrast, if we had naively predicted the most frequent class in the test set, your mean accuracy rate was 0.54 with the worst accuracy rate being 0.53 and the best accuracy rate being 0.555.

## Subject Heterogeneity (CHECK SPELLING)

```{r Model Diagnostics of Wrist Only Model, warning=F, echo=F}
final.model.interaction <- glm(label ~ TEMP_EMP4_MEAN * subject, data = wesad, family = binomial)
pander(final.model.interaction, caption="Table 3")
```

We noticed that some of the subjects' likelihood of being stressed had opposite relationships with respect to their recorded skin temperature from the wristband. For example subject 6 recorded higher skin temperatures during his stress condition while subject 4 recorded lower skin temperatures during his stress condition. In this summary output of our interaction model, you will note that subject's 6 positive interaction effect with temperature counteracts the main effect of temperature on the likelihood of stress. Specifically, for a 0.01 increase in degrees Celsius, we expect that the likelihood that subject 6 is stressed multiplies by a factor of 1.604. However for subject 4, we expect that for a 0.01 increase in degrees Celsisus, their likelihood of being stressed decreases by a factor of 0.525.


# Discussion

Our first goal was to determine whether sensor data are useful in discriminating between stress and amusement conditions. Our estimated accuracy from our first model, which was approximately 0.89, was significantly above the accuracy resulting from naively selecting the most frequent class. For this reason, we have strong evidence to believe sensor data are useful in distinguishing these conditions.

In order to address our second and third goal, which was to determine how and which sensor data are useful in this task, we studied physiological literature discussing stress, conducted feature extraction, and created a logistic regression model motivated by our data analysis. From this, we saw that the mean electrodermal activity and body temperature were significant predictors and interpretted the resulting coefficients.

Next, we examined whether the wristband sensor data alone from the *Empatica E4* was also useful in discriminating between stress and amusement conditions. Ultimately, people are unlikely to wear heavy duty chest sensors everywhere they go, so it is important to determine if a lightweight wristband is as effective. While we faced the limitation of inflated standard errors and convergence challenges that prevented us from using a seemingly useful predictor, we were still able to produce a model with an average accuracy of 0.83. Again, this was significantly above the accuracy resulting from naively selecting the most frequent class. While this accuracy is unsurprisingly slightly lower than that of the chest model, it is clearly still a useful indicator.

Lastly, an important question to answer is the heterogeneity across individuals in the response to stress versus amusement, as physiological responses to stress can differ significantly from person to person. One way to quantify this difference is by analyzing the results of a model with an interaction effect between the subject and a metric. We noticed in our exploratory data analysis that there was an opposite relationship in wrist temperature for some of the subjects. We quantified this difference by creating another logistic regression model and comparing the expected change in the odds as skin temperature increased for Subject 4 and Subject 6. From this, we saw that increasing the skin temperature was associated with lower odds of being stressed for Subject 4 and higher odds for Subject 6.

# Limitations and Looking Ahead

Several of the limitations in the analysis include our inability to cater to each metric's preferred sampling rate, the limited number of affective states, the imprecision in the devices themselves, and the lack of representation from younger and older age groups, and the limited representation of women. For future studies, it will be necessary to examine whether sensor data from wearables is capable of distinguishing other affective states that yield similar physiological responses, such as anger, and to include subjects from a broad range of ethnicities, races, and age groups. Another possible avenue to explore would be testing popular consumer wrist sensors that claim to accurately detect emotion. Finally, a possible improvement to this study could have been conducting nested cross-validation, in which the hyperparameters would be window size/shift, sampling frequency, etc, so a wider range of views on the data are explored.

# Appendix

## Tables

```{r Data Dictionary, eval = TRUE, echo=F}
collapse_rows_dt <- data.frame(Metric = c(rep("ECG (mV)", 3), rep("EDA ($\\mu$s)", 2), rep("EMG (mV)", 6), rep("Temp (C$^\\circ$)", 4),
                                      rep("Resp ($\\%$)", 3), rep("BVP", 4), rep("EDA ($\\mu$s)", 2), rep("Temp (C$^\\circ$)", 2)),
                               Description = linebreak(c(rep("Electrocardiography: 700 Hz", 3), 
                                                         rep("Electrodermal Activity: 700 Hz", 2), 
                                                         rep("Electromyography: 700 Hz", 6),
                                                         rep("Body Temperature: 700 Hz", 4), 
                                                         rep("Respiration: 700 Hz", 3), 
                                                         rep("Blood Volume Pulse: 64 Hz", 4), 
                                                         rep("Electrodermal Activity: 4 Hz", 2), 
                                                         rep("Skin Temperature: 4 Hz", 2))),
                               MSR = linebreak(c(rep("50 Hz", 3), 
                                                         rep("4 Hz", 2), 
                                                         rep("30 Hz", 6),
                                                         rep("1 Hz", 4), 
                                                         rep("10 Hz", 3), 
                                                         rep("1 Hz (HR)", 4), 
                                                         rep("4 Hz", 2), 
                                                         rep("1 Hz", 2))),
                               Features = linebreak(c("Mean", "Std Deviation", "Peaks", 
                                        "Mean" , "Std Deviation", 
                                        "Mean", "Std Deviation", "Range", "Median", "10th Percentile", "90th Percentile", 
                                        "Mean", "Std Deviation", "Range", "Median", 
                                        "Mean",  "Std Deviation", "Peaks", 
                                        "Mean", "Std Deviation", "Heart Rate Variability", "RMSSD of HRV",
                                        "Mean", "Std Deviation", 
                                        "Mean", "Std Deviation")))
kable(collapse_rows_dt, escape=F, booktabs = T, align = "llcc", caption = "Data Dictionary") %>%
  kable_styling(latex_options = c("hold_position")) %>% 
  group_rows(index = c("RespiBAN Chest Sensor" = 18, "Empatica E4 Wrist Sensor" = 8)) %>%
  column_spec(1, bold=T) %>%
  collapse_rows(columns = 1:3, latex_hline = "major", valign = "middle")
```

Note that while both sensors also included accelerometer data, it was not included in this analysis as it was only used to align the data points and distinguish the timestamps of the amusement and stress states. Other studies also have considered this variable and ultimately found it not to be useful, as you can read here [[9]][Bibliography].

For our final model, we decided to use linear interpolation to upsample the the electrocardiography *Empatica E4* data [[8]][Bibliography]. For example, say we observe the values $[2.0, 6.0, 12.0, 24.0]$ with 2 Hz as the current sampling rate (i.e. 2 and 6 are observations from the first second), and we wish to upsample to 4 Hz. We would translate these values to $[2.0, 3.33, 4.66, 6.0, 12.0, 16.0, 20.0, 24.0]$. We tested our model's sensitivity to this decison by also using forward projection (in the example above, forward projection would yield $[2.0, 2.0, 6.0, 6.0, 12.0, 12.0, 16.0, 16.0]$) and saw similar results, which is located in Table ** in the Appendix (REMOVE IF FALSE).

## Plots

#### Distributions of EDA and Temperature Measured at Wrist

```{r fig.width=10, fig.height=4, message=F, echo=F}
# distribution of average body temperature measured at wrist (window = 60s, shift = 0.25s)
ggplot(wesad) +
  geom_histogram(aes(x=TEMP_EMP4_MEAN, fill=label),alpha = 0.6, position = "identity")+
  facet_wrap(~subject, nrow = 3, scales = "free")+
  labs(x = "Body Temperature (??C)",
       title = "Empatica E4 Skin Temperature") 

# distribution of average electrodermal activity measured at wrist (window = 60s, shift = 0.25s)
ggplot(wesad) +
  geom_histogram(aes(x=EDA_EMP4_MEAN, fill=label),alpha = 0.6, position = "identity")+
  facet_wrap(~subject, nrow = 3, scales = "free")+
  labs(x = expression(paste("Electrodermal Activity (",mu,"S)")),
       title = "Empatica E4 Electrodermal Activity")
```

### Chest Binned Residual Plots

```{r fig.width=6, fig.height=4, message=F, echo=F}
arm::binnedplot(x=model.chest.final$EDA_CHEST_MEAN,y=model.chest.final$.resid,
                xlab="RespiBAN Electrodermal Activity", 
                main = "Binned Residual vs. RespiBAN Electrodermal Activity")

arm::binnedplot(x=model.chest.final$Temp_CHEST_MEAN,y=model.chest.final$.resid,
                xlab="RespiBAN Body Temperature", 
                main = "Binned Residual vs. RespiBANBody Temperature")
```

## Bibliography

1. Wray, S. (2017, July 27). Explosion of smart, wearable devices will triple revenue by 2016. Retrieved September 20, 2020, from https://inform.tmforum.org/features-and-analysis/2014/09/explosion-smart-wearable-devices-will-triple-revenue-2016/
2. Lu, T., Fu, C., Ma, M., Fang, C., & Turner, A. (2016, September 14). Healthcare Applications of Smart Watches. A Systematic Review. Retrieved September 20, 2020, from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5052554/
3. Hiner, J. (2020, April 27). How Apple Watch helped fix my toxic level of stress. Retrieved September 20, 2020, from https://www.cnet.com/news/apple-watch-uncovered-my-toxic-stress-level-and-helped-me-fix-it/
4. 5 Things You Should Know About Stress. (n.d.). Retrieved September 20, 2020, from https://www.nimh.nih.gov/health/publications/stress/index.shtml
5. Clark, E. (2019, October 17). New Report Finds That More Than Half of Wearable Users Fear Inaccurate Health Data, Malfunctions; Users Cautioned Against Relying on Devices. Retrieved September 20, 2020, from https://www.prnewswire.com/news-releases/new-report-finds-that-more-than-half-of-wearable-users-fear-inaccurate-health-data-malfunctions-users-cautioned-against-relying-on-devices-300940397.html
6. Weintraub, K. (2016, October 13). Wearable health monitors not always reliable, study shows. Retrieved September 20, 2020, from https://www.usatoday.com/story/news/2016/10/12/wearable-health-monitors-not-always-reliable-study-shows/91922858/
7. Philip Schmidt, Attila Reiss, Robert Duerichen, Claus Marberger, and Kristof Van Laerhoven. 2018. Introducing WESAD, a Multimodal Dataset for Wearable Stress and Affect Detection. In Proceedings of the 20th ACM International Conference on Multimodal Interaction (ICMI '18). Association for Computing Machinery, New York, NY, USA, 400???408. DOI:https://doi.org/10.1145/3242969.3242985
8. https://www.cs.toronto.edu/~guerzhoy/320/lec/upsampling.pdf
9. Gjoreski, M., Lu??trek, M., Gams, M., &amp; Gjoreski, H. (2017, August 10). Monitoring stress with a wrist device using context. Retrieved September 27, 2020, from https://www.sciencedirect.com/science/article/pii/S1532046417301855
10. Mahdiani S, Jeyhani V, Peltokangas M, Vehkaoja A. Is 50 Hz high enough ECG sampling frequency for accurate HRV analysis? Annu Int Conf IEEE Eng Med Biol Soc. 2015;2015:5948-51. doi: 10.1109/EMBC.2015.7319746. PMID: 26737646.
11. Braithwaite, J. J., Watson, D. G., Jones, R., &amp; Rowe, M. (2013). A Guide for Analysing Electrodermal Activity (EDA) &amp; Skin Conductance Responses (SCRs) for Psychological Experiments. Retrieved September 26, 2020, from https://www.biopac.com/wp-content/uploads/EDA-SCR-Analysis.pdf
12. Pourmohammadi, S., &amp; Maleki, A. (2020, May 05). Stress detection using ECG and EMG signals: A comprehensive study. Retrieved September 27, 2020, from https://www.sciencedirect.com/science/article/pii/S0169260719320528
