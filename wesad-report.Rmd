---
title: "Stress Detection in Wearables"
author: "Alice Liao, Anna Darwish, Bernardo Martinez"
date: "9/19/2020"
output: 
  pdf_document:
     latex_engine: xelatex
     number_sections: true
---

```{r, function checking for installed packages, echo=FALSE, results="hide", include=FALSE}
# Validate that all necessary packaged have been downloaded, install otherwise or throw err package DNE
pkgTest <- function(x)
{
  if (!require(x,character.only = TRUE))
  {
    install.packages(x,repos = "http://cran.r-project.org", dep=TRUE)
    if(!require(x,character.only = TRUE)) stop("Package not found")
  }
}
```

```{r Package Test Libraries, echo=FALSE, results="hide", include=FALSE}
pkgTest("dplyr")
pkgTest("ggplot2")
pkgTest("tidyr")
pkgTest("knitr")
pkgTest("kableExtra")
```

```{r Load in Libraries, echo=FALSE, results="hide", include=FALSE}
library(dplyr)
library(ggplot2)
library(tidyr)
library(knitr)
library(kableExtra)
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE)
ggplot2::theme_set(new = theme_bw())
```

# Introduction

In the past few years, the use of wearables have exploded [[1]][Bibliography]. With it, researchers around the globe are exploring how tracking health information via wearables, such as a person???s heart rate, can help gain insight into the person???s physical and emotional state [[2]][Bibliography]. Across many different functionalities, such as tracking workouts or monitoring sleep, wearables also present an exciting opportunity to detect stress. In doing so, wearable users today, such as Apple watch user Jason Hiner, have become more cognizant of their emotional state and worked to improve it [[3]][Bibliography]. Given that stress can lead to long term health issues, such as "heart disease, high blood pressure, diabetes, and ... depression or anxiety" [[4]][Bibliography], it is crucial for us to ensure that wearables can accurately detect stress and distinguish it from other affective states.

However, researchers have found evidence to be skeptical of the accuracy and insights a wearable watch is capable of offering [[5]][Bibliography]. For example, experts at the Cleveland Clinic found that heart-rate data in many popular wearables can be wrong 10-20% of the time [[6]][Bibliography]. While research has been done to examine whether these sensors are capable of detecting excited affective states, such as stress, relative to a subject's baseline state, there are far fewer studies that examine whether these sensors are capable of distinguishing excited affective states from one another, such as stress vs amusement [[7]][Bibliography]. A recent paper was able to generate highly accurate machine learning models that classified wearers' states among baseline, stress, and amusement conditions using an Empatica 4 wristband [[7]][Bibliography]. However, these methods were unable to provide significant insight into the relationship between the most informative metrics and these affective states.

In this paper we hope to expand upon the work done within the Schmidt et. al paper by delving deeper into the relationship between the metrics collected by these sensors and the wearers' affective states with a logistic regression model. Specifically, we hope to accomplish the following goals:

1. Determine whether sensor data are useful in discriminating between stress and amusement conditions
2. Understand and describe how sensor data are useful in discriminating between stress and amusement
3. Determine which types and combination(s) of sensor data are most useful in discriminating between stress and amusement
4. Determine whether we can detect stress (vs amusement) only using the wrist-worn wearable
5. Quantify the heterogeneity across individuals in the response to stress versus amusement

# Data

## Collection Overview

For the purposes of this paper, we will use the biological definition of stress: an affective state defined to be the 'nonspecific response of the body to any demand upon it' [[7][Bibliography]. The data used in this paper was collected by attaching a *RespiBAN Professional* chest device and *Empatica E4* wristband to 17 graduate students. Due to sensor malfunctions, two of the subjects' data had to be discarded, for a final total of 15 subjects. Three of these subjects were women while the rest were men, and their ages ranged from 25 years old to 35 years old. This experiment sought to elicit three different affective states: neutral, stress, and amusement, and accomplished this by having the subjects perform stressful tasks (e.g public speaking) and amusing tasks (e.g watching funny videos) with breaks of meditation between sessions to restore subjects to their baseline. The stress-condition tasks and amusement-condition tasks were interchanged to avoid effects of order [[7]][Bibliography].

In the Appendix, you can see a full data dictionary in Table 1 that defines the metrics, their sampling rates, and any extracted features. Finally, it is important to note that for Subject 3, there appears to have been a brief malfunction (over a span of approximately 0.1 seconds during stressed condition) that led to impossible measurements, such as temperatures of -273$^\circ$ C. We chose to treat these ranges as missing values and also used linear interpolation to replace these faulty measurements.

## Exploratory Data Analysis

We plotted the distributions of predictors for each of the subjects and realized for some people, certain predictors serve as perfect separators for amused vs. stressed conditions (i.e. the distributions under the two conditions are significantly different or separated), but that's not always the case. Among all predictors, electrodermal activity (EDA) and temperature are the two physiological signals that appear to be separators for most of the subjects. 

# Methods

Our first step with this dataset involved aligning the *RespiBAN* data and *Empatica E4* data. For the *RespiBAN* data, each metric was collected at 700Hz. Across all metrics, 700Hz was well above the minimum sampling rate [[8]][Bibliography], [[9]][Bibliography], [[10]][Bibliography], [[11]][Bibliography], which is defined to be the minimum number of samples needed to glean precise summary statistics per second. For more detail on the minimum sampling rates (MSRs) across the different metrics, please reference Table 1 in the Appendix. Despite these different MSRs, these metrics ultimately needed to be aligned to represent distinct and whole samples. We selected to down sample to 50 Hz, the MSR of Electrocardiography, as the results of our exploratory data analysis suggests it may be the most useful metric in distinguishing amusement from stress. Further, selecting this sampling rate accomodates all of the metrics' minimum sampling rates and therefore limits the risk of excluding useful information early on. (REMOVE IF ULTIMATELY FALSE) Please reference Table ** later on to compare the results of our final models to those with a sampling rate of 25Hz.

For our final model, we decided to use linear interpolation to upsample the *Empatica E4* data [[8]][Bibliography]. For example, say we observe the values $[2.0, 6.0, 12.0, 24.0]$ with 2 Hz as the current sampling rate (i.e. 2 and 6 are observations from the first second), and we wish to upsample to 4 Hz. We would translate these values to $[2.0, 3.33, 4.66, 6.0, 12.0, 16.0, 20.0, 24.0]$. We tested our model's sensitivity to this decison by also using forward projection (in the example above, forward projection would yield $[2.0, 2.0, 6.0, 6.0, 12.0, 12.0, 16.0, 16.0]$) and saw similar results, which is located in Table ** in the Appendix (REMOVE IF FALSE).

Finally, we performed feature extraction from these raw sensor values by calculating general transformations, such as mean and standard deviation, over a 60 second window and 0.25 second window shift. Please refer to Table ** in the Appendix for more details on other transformations we explored in generating our models. This decision was motivated by the Schmidt et. al paper's choice in window size and shift. We also tested our models' sensitivity to this decision with a 60 second window and 0.5 second window shift and a 30 second window with a 0.25 second window shift. The results of these window and shift pairings can be found in the Appendix in Table ** (REMOVE IF FALSE).

For this paper, we have decided to generate several logistic regression models to better understand and interpret the relationship between these metrics. We began by exploring histograms and scatterplots of our metrics. From this we started with a model with the following predictors: EDA, Body Temperature (since exploratory analysis suggests these two are likely to be the most useful classifiers), and Subject and ran 10-fold cross-validation on our dataset to estimate the test error. Note that it was necessary to include the subject id in order for us to be able to treat our observations as independent. Then we performed forward model selection to check if we missed any other important predictors that can improve the accuracy of prediction. In addition, since both *Empatica E4* wrist sensor and *RespiBan* chest sensor provide readings for EDA and Body Temperature, we can compare which type of sensor is more useful in discriminating between stress and amusement and if wrist data alone is enough. 

# Results
(report model result, MSE/accuracy)


# Discussion
(compare different models, interpretation of coefficient, answer project goals)


(model diagonistics)
AUC Curves or ROC Curves

# Conclusion

To summarize our final results, we found that ... were the most useful predictors in distinguishing stress from amusement in these subjects. Further, we found that the data from the *Empatica E4* wrist sensor alone was ____ than the data from the *Empatica E4* and *RespiBAN* combined. Finally, for the predictors ..., there was a significant interaction effect between that metric and at least one of the subjects. This suggests that there may be other covariates or metrics that are required to make a generalizable model.

Several of the limitations in the analysis include our inability to cater to each metric's preferred sampling rate, the limited number of affective states, the imprecision in the devices themselves, and the lack of representation from younger and older age groups, and the limited representation of women. For future studies, it will be necessary to examine whether sensor data from wearables is capable of distinguishing other affective states that yield similar physiological responses, such as anger, and to include subjects from a broad range of ethnicities, races, and age groups. Another possible avenue to explore would be testing popular consumer wrist sensors that claim to accurately detect emotion. Finally, a possible improvement to this study could have been conducting nested cross-validation, in which the hyperparameters would be window size/shift, sampling frequency, etc, so a wider range of views on the data are explored.

# Appendix

## Tables

```{r Data Dictionary, eval = TRUE}
collapse_rows_dt <- data.frame(Metric = c(rep("ECG (mV)", 3), rep("EDA ($\\mu$s)", 2), rep("EMG (mV)", 6), rep("Temp (C$^\\circ$)", 4),
                                      rep("Resp ($\\%$)", 3), rep("BVP", 4), rep("EDA ($\\mu$s)", 2), rep("Temp (C$^\\circ$)", 2)),
                               Description = linebreak(c(rep("Electrocardiography: 700 Hz", 3), 
                                                         rep("Electrodermal Activity: 700 Hz", 2), 
                                                         rep("Electromyography: 700 Hz", 6),
                                                         rep("Body Temperature: 700 Hz", 4), 
                                                         rep("Respiration: 700 Hz", 3), 
                                                         rep("Blood Volume Pulse: 64 Hz", 4), 
                                                         rep("Electrodermal Activity: 4 Hz", 2), 
                                                         rep("Skin Temperature: 4 Hz", 2))),
                               MSR = linebreak(c(rep("50 Hz", 3), 
                                                         rep("24 Hz", 2), 
                                                         rep("30 Hz", 6),
                                                         rep("1 Hz", 4), 
                                                         rep("10 Hz", 3), 
                                                         rep("1 Hz (HR)", 4), 
                                                         rep("24 Hz", 2), 
                                                         rep("1 Hz", 2))),
                               Features = linebreak(c("Mean", "Std Deviation", "Peaks", 
                                        "Mean" , "Std Deviation", 
                                        "Mean", "Std Deviation", "Range", "Median", "10th Percentile", "90th Percentile", 
                                        "Mean", "Std Deviation", "Range", "Median", 
                                        "Mean",  "Std Deviation", "Peaks", 
                                        "Mean", "Std Deviation", "Heart Rate Variability", "RMSSD of HRV",
                                        "Mean", "Std Deviation", 
                                        "Mean", "Std Deviation")))
kable(collapse_rows_dt, escape=F, booktabs = T, align = "llcc", caption = "Data Dictionary") %>%
  kable_styling(latex_options = c("hold_position")) %>% 
  group_rows(index = c("RespiBAN Chest Sensor" = 18, "Empatica E4 Wrist Sensor" = 8)) %>%
  column_spec(1, bold=T) %>%
  collapse_rows(columns = 1:3, latex_hline = "major", valign = "middle")
```

Note that while both sensors also included accelerometer data, it was not included in this analysis as it was only used to align the data points and distinguish the timestamps of the amusement and stress states. Other studies also have considered this variable and ultimately found it not to be useful, as you can read here [[9]][Bibliography].


## Bibliography

1. Wray, S. (2017, July 27). Explosion of smart, wearable devices will triple revenue by 2016. Retrieved September 20, 2020, from https://inform.tmforum.org/features-and-analysis/2014/09/explosion-smart-wearable-devices-will-triple-revenue-2016/
2. Lu, T., Fu, C., Ma, M., Fang, C., & Turner, A. (2016, September 14). Healthcare Applications of Smart Watches. A Systematic Review. Retrieved September 20, 2020, from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5052554/
3. Hiner, J. (2020, April 27). How Apple Watch helped fix my toxic level of stress. Retrieved September 20, 2020, from https://www.cnet.com/news/apple-watch-uncovered-my-toxic-stress-level-and-helped-me-fix-it/
4. 5 Things You Should Know About Stress. (n.d.). Retrieved September 20, 2020, from https://www.nimh.nih.gov/health/publications/stress/index.shtml
5. Clark, E. (2019, October 17). New Report Finds That More Than Half of Wearable Users Fear Inaccurate Health Data, Malfunctions; Users Cautioned Against Relying on Devices. Retrieved September 20, 2020, from https://www.prnewswire.com/news-releases/new-report-finds-that-more-than-half-of-wearable-users-fear-inaccurate-health-data-malfunctions-users-cautioned-against-relying-on-devices-300940397.html
6. Weintraub, K. (2016, October 13). Wearable health monitors not always reliable, study shows. Retrieved September 20, 2020, from https://www.usatoday.com/story/news/2016/10/12/wearable-health-monitors-not-always-reliable-study-shows/91922858/
7. Philip Schmidt, Attila Reiss, Robert Duerichen, Claus Marberger, and Kristof Van Laerhoven. 2018. Introducing WESAD, a Multimodal Dataset for Wearable Stress and Affect Detection. In Proceedings of the 20th ACM International Conference on Multimodal Interaction (ICMI '18). Association for Computing Machinery, New York, NY, USA, 400???408. DOI:https://doi.org/10.1145/3242969.3242985
8. https://www.cs.toronto.edu/~guerzhoy/320/lec/upsampling.pdf
9. Gjoreski, M., Lu??trek, M., Gams, M., &amp; Gjoreski, H. (2017, August 10). Monitoring stress with a wrist device using context. Retrieved September 27, 2020, from https://www.sciencedirect.com/science/article/pii/S1532046417301855
10. Mahdiani S, Jeyhani V, Peltokangas M, Vehkaoja A. Is 50 Hz high enough ECG sampling frequency for accurate HRV analysis? Annu Int Conf IEEE Eng Med Biol Soc. 2015;2015:5948-51. doi: 10.1109/EMBC.2015.7319746. PMID: 26737646.
11. Braithwaite, J. J., Watson, D. G., Jones, R., &amp; Rowe, M. (2013). A Guide for Analysing Electrodermal Activity (EDA) &amp; Skin Conductance Responses (SCRs) for Psychological Experiments. Retrieved September 26, 2020, from https://www.biopac.com/wp-content/uploads/EDA-SCR-Analysis.pdf
12. Pourmohammadi, S., &amp; Maleki, A. (2020, May 05). Stress detection using ECG and EMG signals: A comprehensive study. Retrieved September 27, 2020, from https://www.sciencedirect.com/science/article/pii/S0169260719320528
