---
title: "Stress Detection in Wearables"
author: "Alice Liao, Anna Darwish, Bernardo Martinez"
date: "9/19/2020"
output: 
  pdf_document:
     latex_engine: xelatex
     number_sections: true
---

```{r, Function checking for installed packages, echo=FALSE, results="hide", include=FALSE}
# Validate that all necessary packaged have been downloaded, install otherwise or throw err package DNE
pkgTest <- function(x)
{
  if (!require(x,character.only = TRUE))
  {
    install.packages(x,repos = "http://cran.r-project.org", dep=TRUE)
    if(!require(x,character.only = TRUE)) stop("Package not found")
  }
}
```

```{r Package Test Libraries, echo=FALSE, results="hide", include=FALSE}
pkgTest("arm")
pkgTest("broom")
pkgTest("cowplot")
pkgTest("dplyr")
pkgTest("ggplot2")
pkgTest("knitr")
pkgTest("kableExtra")
pkgTest("MASS")
pkgTest("msm")
pkgTest("plotROC")
pkgTest("pROC")
pkgTest("tidyr")
pkgTest("pander")
```

```{r Load in Libraries, echo=FALSE, results="hide", include=FALSE}
library(arm)
library(broom)
library(cowplot)
library(dplyr)
library(ggplot2)
library(knitr)
library(kableExtra)
library(MASS)
library(msm)
library(plotROC)
library(pROC)
library(tidyr)
library(pander)
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE)
```

```{r Load data, include=F}
wesad <- read.csv("merged_wesad_data.csv")
wesad <- wesad %>%
  mutate(label = as.factor(label),
         subject = as.factor(subject))
```

# Introduction

In the past few years, the use of wearables has exploded [[1]][Bibliography]. With it, researchers around the globe are exploring how tracking health information via wearables, such as a person's heart rate, can help gain insight into their physical and emotional states [[2]][Bibliography]. Across many different functionalities, such as tracking workouts or monitoring sleep, wearables also present an exciting opportunity to detect stress. In doing so, wearable users today, such as Apple watch user Jason Hiner, have become more cognizant of their emotional state and worked to improve it [[3]][Bibliography]. Given that stress can lead to long term health issues, such as heart disease, high blood pressure, diabetes, and depression or anxiety [[4]][Bibliography], it is critical for us to ensure that wearables can accurately detect stress and distinguish it from other affective states.

However, researchers have found evidence to be skeptical of the accuracy and insights a wearable watch is capable of offering [[5]][Bibliography]. For example, experts at the Cleveland Clinic found that heart-rate data in many popular wearables can be wrong 10-20% of the time [[6]][Bibliography]. While research has been done to examine whether these sensors are capable of detecting excited affective states, such as stress, relative to a subject's baseline state, there are far fewer studies that examine whether these sensors are capable of distinguishing excited affective states from one another, such as stress vs amusement [[7]][Bibliography]. A recent paper by Schmidt et. al was able to generate highly accurate machine learning models that classified wearers' states among baseline, stress, and amusement conditions using an Empatica 4 wristband [[7]][Bibliography]. However, these methods were unable to provide significant insight into the relationship between the most informative metrics and these affective states.

In this paper we hope to expand upon the work done within the Schmidt et. al paper by delving deeper into the relationship between the metrics collected by these sensors and the wearers' affective states with a logistic regression model. Specifically, we hope to accomplish the following goals:

1. Determine whether sensor data are useful in discriminating between stress and amusement conditions
2. Understand and describe how sensor data are useful in discriminating between stress and amusement
3. Determine which types and combination(s) of sensor data are most useful in discriminating between stress and amusement
4. Determine whether we can detect stress (vs amusement) only using the wrist-worn wearable
5. Quantify the heterogeneity across individuals in the response to stress versus amusement

# Data

## Collection Overview

For the purposes of this paper, we will use the biological definition of stress: an affective state defined to be the 'nonspecific response of the body to any demand upon it' [[7]][Bibliography]. The data used in this paper were collected by attaching a *RespiBAN Professional* chest device and *Empatica E4* wristband to 17 graduate students. Due to sensor malfunctions, two of the subjects' data had to be discarded, for a final total of 15 subjects. Three of these subjects were women while the rest were men, and their ages ranged from 25 years old to 35 years old. This experiment sought to elicit three different affective states: neutral, stress, and amusement, and accomplished this by having the subjects perform stressful tasks (e.g public speaking) and amusing tasks (e.g watching funny videos) with breaks of meditation between sessions to restore subjects to their baseline. The stress-condition tasks and amusement-condition tasks were interchanged to avoid effects of order [[7]][Bibliography].

In the Appendix, you can see a full data dictionary in Table 5 that defines the metrics, their sampling rates, and any extracted features. Finally, it is important to note that for Subject 3, there appears to have been a brief malfunction (over a span of approximately 0.1 seconds during stress condition) that led to impossible measurements, such as temperatures of -273$^\circ$C. We chose to treat these ranges as missing values and also used linear interpolation to replace these faulty measurements.

## Exploratory Data Analysis

We plotted the distributions of predictors for each of the subjects and realized for some people, certain metrics serve as perfect separators for amused vs. stressed conditions (i.e. the distributions under the two conditions are significantly different or separated), but that's not always the case. Among all predictors, electrodermal activity (EDA) and temperature are the two physiological signals that appear to be separators for most of the subjects. 

```{r loadEDAgraphs, fig.width=10, fig.height=4, message=F, echo=F}
# distribution of average body temperature measured at chest (window = 60s, shift = 0.25s)
ggplot(wesad) +
  geom_histogram(aes(x=Temp_CHEST_MEAN, fill=label),alpha = 0.6, position = "identity")+
  facet_wrap(~subject, nrow = 3, scales = "free")+
  labs(x = expression("Body Temperature " (degree*C)),
       title = "RespiBan Average Skin Temperature (Over Windows of 60 Seconds)",
       caption="Figure 1") + theme(plot.caption = element_text(hjust = 0.5, vjust = -0.5, size = 18))
# distribution of average electrodermal activity measured at wrist (window = 60s, shift = 0.25s)
ggplot(wesad) +
  geom_histogram(aes(x=EDA_CHEST_MEAN, fill=label),alpha = 0.6, position = "identity")+
  facet_wrap(~subject, nrow = 3, scales = "free")+
  labs(x = expression(paste("Electrodermal Activity (",mu,"S)")),
       title = "RespiBan Average Electrodermal Activity (Over Windows of 60 Seconds)",
       caption="Figure 2") + theme(plot.caption = element_text(hjust = 0.5, vjust = -0.5, size = 18))
```

From Figure 1 we see body temperatures are different in amused vs stressed states. For some subjects, such as Subject 10 and 11, the difference is more pronounced in that the distributions of body temperatures are completely separated by the two states. Similarly in Figure 2 we observe different electrodermal acitivities in different emotional states. The histograms also suggest not everyone reacts to amusement and stress in the same way. In general, it seems more sweat (higher EDA) is associated with stress, but Subject 14 could have high EDA but was amaused too. As for temperature, some subjects had higher temperature under stress (e.g. Subject 10 and Subject 15) whereas some had lower temperature when amused (e.g. Subject 11 and Subject 17). Skin temperature and EDA measured at wrist appear to be separators too and their distributions can be found in Appendix.  

# Methods

Our first step with this dataset involved aligning the *RespiBAN* data and *Empatica E4* data. For the *RespiBAN* data, each metric was collected at 700Hz. Across all metrics, 700Hz was well above the minimum sampling rate [[8]][Bibliography], [[9]][Bibliography], [[10]][Bibliography], [[11]][Bibliography], which is defined to be the minimum number of samples needed to glean precise feature extractions. For more detail on the minimum sampling rates (MSRs) across the different metrics, please reference Table 1 in the Appendix. Despite these different MSRs, these metrics ultimately needed to be aligned to represent distinct and whole samples. We selected to downsample to 4 Hz, which has been documented as the minimum sampling rate of electrodermal activity (EDA). From our data exploration, EDA appeared to be a key metric in distinguishing stress and amusement, so we chose to prioritize it when downsampling.

We accomplished this downsampling by calculating our features over a window of one minute with a shift of 0.25 seconds. This was motivated by the Schmidt et. al's paper's window and shift decisions. Please refer to Table 1 in the Appendix for more details on the other metrics and the transformations we explored. Additionally, please reference Tables 6-9 later on to compare the results of our final chest and wrist models to those with a sampling rate of 2 Hz for sensitivity analysis, which we accomplished with a 60 second window and 0.5 second shift.

For this paper, we have decided to generate several logistic regression models to better understand and interpret the relationship between these metrics. We began by exploring histograms and scatterplots of our metrics. From this we started with a model with the following predictors: RespiBAN EDA, RespiBAN Body Temperature, and Subject. We need to include Subject to ensure independence among our samples, as the observations within the same subject were highly correlated.

When we were exploring models for the wrist data, we intially began with the mean EDA as a predictor, as it perfectly separated the stress and amused condition for many of the subjects (see Appendix). However, this caused significant model instability and severely inflated the standard errors. For that reason, we explored other statistical features of EDA and noticed that the standard deviation of EDA also performed quite well. For subjects such as Subjects 2 and 15, who did not have as strong of separation when only using the standard deviation of EDA, we noticed the mean wrist temperature served as a useful metric.

To validate both models, we used confusion matrices, ROC curves, and binned residual plots to evaluate our model assumptions. Finally, we ran 10-fold cross-validation on each predictive model to estimate the test error. Finally, for quantifying heterogeneity, we explored interaction effects with skin temperature.

\newpage

# Results

## Chest & Wrist Model

```{r Generate and Test Wrist and Chest Model, warning=F, echo=F}
wesad <- within(wesad, subject <- relevel(subject, ref = "S2"))

model.chest.final <- glm(label ~ EDA_CHEST_MEAN + Temp_CHEST_MEAN + subject, data = wesad, family = binomial)
pander(model.chest.final, caption = "Chest Model Output")
```

$$
\begin{aligned}
log(\frac{P_i(Stress)}{1 - P_i(Stress)}) = \beta_0 +  \beta_1\overline{EDA_i}^{RB} + \beta_2\overline{TEMP_i}^{RB} + \Sigma_{j \in S}\beta_{j}I(Subject = Subject_j) \\
S = \{3,4,...,11,13,...17\}
\end{aligned}
$$

Note that the $RB$ superscipt indicates that these measures came from the RespiBAN, and the baseline subject for comparison was Subject 2.

For every 0.1 $\mu s$ increase in EDA from the RespiBAN, we expect that the odds that the subject is stressed multiplies by a factor of `r round(exp(.757090),3)`. For every 0.01 degree Celsius increase in body temperature, we predict that the likelihood the subject is stressed decreases by a factor of `r round(exp(-3.37990 * 0.01),3)`. We will not be interpreting the subject coefficients as they were included in the model for independence purposes.

This model also provided statistically significant values for all the coefficients used. 

```{r Chest Model Diagnostics CF Matrix, echo=F}
threshold <- 0.5
model.chest.final <- augment(model.chest.final, type.predict = "response")

model.chest.final %>%
  mutate(Chest = if_else(.fitted > threshold, "Stressed", "Amused")) %>%
  group_by(label, Chest) %>%
  summarise(n = n()) %>%
  spread(label, n) %>%
  kable(format="markdown")
```

From the confusion matrix, we can see that we are slightly more likely to produce a false positive with this model, i.e. classifying someone as stressed when they are amused. This is likely due to the fact that we have about 1.8 times as many stress-condition samples than amuse-condition samples.

```{r  Chest Model Diagnostics ROC, fig.height=3, fig.width=3, fig.align='center', message=F, echo=F}
ggplot(model.chest.final, aes(d = as.numeric(label), m = .fitted)) + 
  geom_roc(n.cuts = 0) + 
  geom_abline(intercept = 0) + labs(title="Chest Model: ROC Curve", x="False Positive Fraction", y="True Positive Fraction", caption="Figure 3") +
  theme(plot.caption = element_text(hjust = 0.5, vjust = -0.5, size = 14))
```

```{r  Chest Model Diagnostics Binned Residuals, fig.height=3, fig.width=6, fig.align='center', message=F, echo=F}
arm::binnedplot(x=model.chest.final$.fitted,y=model.chest.final$.resid,
                xlab="Predicted Probabilities", 
                main = "Figure 4: Binned Residual vs. Predicted Probabilities",
                cex.main=0.9, cex.lab=0.8)
```

```{r Chest Model CV, message=F, echo=F}
wesad_random<-wesad[sample(nrow(wesad)),]
folds <- cut(seq(1,nrow(wesad_random)), breaks=10, labels=FALSE)
chest_accuracies = c()
chest_random_selection_accuracies <- c()
for(i in 1:10){
  # Segement your data by fold using the which() function 
  test.indices <- which(folds==i,arr.ind=TRUE)
  test <- wesad_random[test.indices, ]
  train <- wesad_random[-test.indices, ]
  
  # Fitting the linear model using train data
  glm.fit <- glm(label ~ EDA_CHEST_MEAN + Temp_CHEST_MEAN + subject, data = train, family = binomial)
  
  # Calculating accuracy using test data
  glm.probs <- predict(glm.fit, test, type = "response")
  glm.pred <- rep("Amused", nrow(test))
  glm.pred[glm.probs > 0.5] <- "Stressed" # if prob > 0.5, predicted label = stressed
  
  # ensure randomized predictions for each fold with runif function
  set.seed(i)
  chest_accuracies <- c(chest_accuracies, (sum(diag(table(glm.pred, test$label)))/nrow(test)))
  
  stressed.proportion <- sum(as.numeric(test$label) - 1)/nrow(test)
  
  guess = 1
  if (stressed.proportion < 0.5){
    guess = 0
  }
  random.guesses = data.frame(actual=(as.numeric(test$label) - 1))
  random.guesses$estimates <- rep(guess,nrow(random.guesses))
  chest_random_selection_accuracies <- c(chest_random_selection_accuracies, (1-sum(abs(random.guesses$estimates-random.guesses$actual))/nrow(test)))
}
```

From the ROC curve in Figure 3, we achieved an AUC of approximately 0.96, which indicates that our model has a relatively high accuracy for predicting the response. 

For the binned residuals vs predicted probabilities in Figure 4, we see that there appears to be a strong cubic curve. While this may suggest that we should take our predictors to a higher power, we could find any literature to motivate such a decision. Instead, we believe there are external factors that these metrics could not capture in this model. Please reference the Appendix for the remaining binned residual plots. When examining the binned residuals against the mean EDA, we see that beyond 9 $\mu S$, the residuals go to 0. This is likely due to the perfect separation we saw in our data exploration. Before this, the scatter appears to be random about the 0 line. Finally, the binned residuals against body temperature show that we are generally incurring false negatives on the extreme ends of body temperature and incurring false positives between 33$^\circ$C and 35$^\circ$C.

After performing 10-fold cross validation, the average accuracy rate on the test sets was `r round(mean(chest_accuracies),3)` with the worst accuracy rate being `r round(min(chest_accuracies),3)` and the best accuracy rate being `r round(max(chest_accuracies),3)`. In contrast, if we had naively predicted the most frequent class in the test set, our mean accuracy rate was `r round(mean(chest_random_selection_accuracies),3)` with the worst accuracy rate being `r round(min(chest_random_selection_accuracies),3)` and the best accuracy rate being `r round(max(chest_random_selection_accuracies),3)`.

```{r Generate Wrist Model, warning=F, echo=F}
model.wrist.final <- glm(label ~ EDA_EMP4_STDDEV + TEMP_EMP4_MEAN + subject, data = wesad, family = binomial)
pander(model.wrist.final, caption = "Wrist Model Output")
```

$$
\begin{aligned}
log(\frac{P_i(Stress)}{1 - P_i(Stress)}) = \beta_0 +  \beta_1 * SD(EDA_i)^{E4} + \beta_2*\overline{TEMP_i}^{E4} + \Sigma_{j \in S}\beta_{j}*I(Subject = Subject_j) \\
S = \{3,4,...,11,13,...17\}
\end{aligned}
$$

Note that the $E4$ superscipt indicates that these measures came from the *Empatica E4* wristband, and we have kept the same baseline with Subject 2. 

For every 0.1 $\mu s$ increase in standard deviation of the EDA from the *Empatica E4*, we expect that the odds that the subject is stressed multiplies by a factor of `r round(exp(3.106743),3)`. For every 0.01 degree Celsius increase in skin temperature, we predict that the likelihood the subject is stressed decreases by a factor of `r round(exp(0.06455 * 0.01),3)`. Again, we will not be interpreting the subject coefficients per the aforementioned reason.

```{r  Wrist Model Diagnostics CF Matrix, echo=F, message=F}
threshold <- 0.5
model.wrist.final <- augment(model.wrist.final, type.predict = "response")

model.wrist.final %>%
  mutate(Wrist = if_else(.fitted > threshold, "Stressed", "Amused")) %>%
  group_by(label, Wrist) %>%
  summarise(n = n()) %>%
  spread(label, n) %>%
  kable(format="markdown")
```

From the confusion matrix, we are again slightly more likely to produce a false positive with this model.

```{r  Wrist Model Diagnostics ROC, echo=F, message=F, fig.height=3, fig.width=3, fig.align='center'}
threshold <- 0.5
ggplot(model.wrist.final, aes(d = as.numeric(label), m = .fitted)) + 
  geom_roc(n.cuts = 0) + 
  geom_abline(intercept = 0) + labs(title="Wrist Model: ROC Curve", x="False Positive Fraction", y="True Positive Fraction", caption="Figure 5") +
  theme(plot.caption = element_text(hjust = 0.5, vjust = -0.5, size = 14))
```

```{r  Wrist Model Diagnostics Binned Plot, echo=F, message=F, fig.height=3, fig.width=6, fig.align='center'}
arm::binnedplot(x=model.wrist.final$.fitted,y=model.wrist.final$.resid,
                xlab="Predicted Probabilities", 
                main = "Figure 6: Binned Residual vs. Predicted Probabilities",
                cex.main=0.9, cex.lab=0.8)
```

```{r Wrist Model CV, message=F, echo=F}
wesad_random<-wesad[sample(nrow(wesad)),]
folds <- cut(seq(1,nrow(wesad_random)), breaks=10, labels=FALSE)
wrist_accuracies = c()
wrist_random_selection_accuracies <- c()
for(i in 1:10){
  # Segement your data by fold using the which() function 
  test.indices <- which(folds==i,arr.ind=TRUE)
  test <- wesad_random[test.indices, ]
  train <- wesad_random[-test.indices, ]
  
  # Fitting the linear model using train data
  glm.fit <- glm(label ~ EDA_EMP4_STDDEV + TEMP_EMP4_MEAN + subject, data = train, family = binomial)
  
  # Calculating accuracy using test data
  glm.probs <- predict(glm.fit, test, type = "response")
  glm.pred <- rep("Amused", nrow(test))
  glm.pred[glm.probs > 0.5] <- "Stressed" # if prob > 0.5, predicted label = stressed
  # ensure randomized predictions for each fold with runif function
  
  set.seed(i)
  wrist_accuracies <- c(wrist_accuracies, (sum(diag(table(glm.pred, test$label)))/nrow(test)))
  
  stressed.proportion <- sum(as.numeric(test$label) - 1)/nrow(test)
  
  random.guesses = data.frame(actual=(as.numeric(test$label) - 1))
  random.guesses$estimates <- runif(nrow(test),0,1)
  random.guesses <- random.guesses %>% mutate(estimates = case_when(estimates < (1 - stressed.proportion) ~ 0, TRUE ~ 1))
  wrist_random_selection_accuracies <- c(wrist_random_selection_accuracies, (1-sum(abs(random.guesses$estimates-random.guesses$actual))/nrow(test)))
}
```

From the ROC curve in Figure 5, we achieved an AUC of approximately 0.9273, which indicates that our model has a relatively high accuracy for predicting the response. 

For the binned residuals vs predicted probabilities, we see that there appears to be another strong cubic curve. Again, while this may suggest that we should take our predictors to a higher power, we could not find any literature to motivate such a decision among the predictors in this model. Instead, we believe there are external factors that these metrics could not capture in this model. Please reference the Appendix for the remaining binned residual plots. When examining the binned residuals against the standard deviation of the EDA, we see another strong curve along with significantly low residuals. The reason for this may be due to convergence issues that resulted from perfect separation for some of the subjects. Finally, the binned residuals against skin temperature show a generally random scatter, excluding a brief interval between 31$^\circ$C  and 32$^\circ$C. Additionally, we also have a few significantly large residuals towards 35$^\circ$C.

After performing 10-fold cross validation, the average accuracy rate on the test sets was `r round(mean(wrist_accuracies),3)` with the worst accuracy rate being `r round(min(wrist_accuracies),3)` and the best accuracy rate being `r round(max(wrist_accuracies),3)`. In contrast, if we had naively predicted the most frequent class in the test set, our mean accuracy rate was `r round(mean(wrist_random_selection_accuracies),3)` with the worst accuracy rate being `r round(min(wrist_random_selection_accuracies),3)` and the best accuracy rate being `r round(max(wrist_random_selection_accuracies),3)`.

## Subject Heterogeneity

```{r Model Diagnostics of Wrist Only Model, warning=F, include=F}
final.model.interaction <- glm(label ~ TEMP_EMP4_MEAN * subject, data = wesad, family = binomial)
```

We noticed that some of the subjects' likelihood of being stressed had opposite relationships with respect to their recorded skin temperature from the wristband. For example subject 6 recorded higher skin temperatures during his stress condition while subject 4 recorded lower skin temperatures during his stress condition. Please reference Table 10 in the Appendix for this model, which includes mean skin temperature and an interaction term with subject. In this summary output of our interaction model, you will note that subject's 6 positive interaction effect with temperature counteracts the main effect of temperature on the likelihood of stress. Specifically, for a 0.01 increase in degrees Celsius, we expect that the likelihood that subject 6 is stressed multiplies by a factor of 1.604. However for subject 4, we expect that for a 0.01 increase in degrees Celsisus, their likelihood of being stressed decreases by a factor of 0.525.

# Discussion

Our first goal was to determine whether sensor data are useful in discriminating between stress and amusement conditions. Our estimated accuracy from our first model, which was approximately `r round(mean(chest_accuracies),3)`, was significantly above the accuracy resulting from naively selecting the most frequent class. For this reason, we have strong evidence to believe sensor data are useful in distinguishing these conditions.

In order to address our second and third goal, which was to determine how and which sensor data are useful in this task, we studied physiological literature discussing stress, conducted feature extraction, and created a logistic regression model motivated by our data analysis. From this, we saw that the mean electrodermal activity and body temperature were significant predictors and interpretted the resulting coefficients.

Next, we examined whether the wristband sensor data from the *Empatica E4* was also useful in discriminating between the conditions alone, as people are unlikely to consistently wear heavy duty chest sensors. While we faced the limitation of inflated standard errors and convergence challenges that prevented us from using a seemingly useful predictor, we were still able to produce a model with an average accuracy of `r round(mean(wrist_accuracies),3)`. Again, this was significantly above the accuracy resulting from naively selecting the most frequent class. While this accuracy is unsurprisingly slightly lower than that of the chest model, it is clearly still a useful indicator.

Lastly, an important question to answer is the heterogeneity across individuals in the response to stress versus amusement, as physiological responses to stress can differ significantly from person to person. We noticed in our exploratory data analysis that there was an opposite relationship in wrist temperature for some of the subjects. We quantified this difference by creating another logistic regression model and comparing the expected change in the odds as skin temperature increased for Subject 4 and Subject 6. From this, we saw that higher skin temperatures were associated with lower odds of being stressed for Subject 4 and higher odds for Subject 6.

# Limitations and Looking Ahead

Several of the limitations in the analysis include our inability to cater to each metric's preferred sampling rate, the limited number of affective states, the imbalance of conditions in the dataset, the imprecision in the devices themselves, the lack of representation from younger and older age groups, and the limited representation of women. For future studies, it will be necessary to examine whether sensor data from wearables is capable of distinguishing other affective states that yield similar physiological responses, such as anger, and to include subjects from a broad range of ethnicities, races, and age groups. Another possible avenue to explore would be testing popular consumer wrist sensors that claim to accurately detect emotion. Finally, a possible improvement to this study could have been conducting nested cross-validation, in which the hyperparameters would be window size/shift, sampling frequency, etc, so a wider range of views on the data are explored.

\newpage

# Appendix

## Tables

```{r Data Dictionary, echo=F}
collapse_rows_dt <- data.frame(Metric = c(rep("ECG (mV)", 2), rep("EDA ($\\mu$s)", 3), rep("EMG (mV)", 3), rep("Temp (C$^\\circ$)", 3),
                                      rep("Resp ($\\%$)", 2), rep("BVP", 4), rep("EDA ($\\mu$s)", 3), rep("Temp (C$^\\circ$)", 3)),
                               Description = linebreak(c(rep("Electrocardiography: 700 Hz", 2), 
                                                         rep("Electrodermal Activity: 700 Hz", 3), 
                                                         rep("Electromyography: 700 Hz", 3),
                                                         rep("Body Temperature: 700 Hz", 3), 
                                                         rep("Respiration: 700 Hz", 2), 
                                                         rep("Blood Volume Pulse: 64 Hz", 4), 
                                                         rep("Electrodermal Activity: 4 Hz", 3), 
                                                         rep("Skin Temperature: 4 Hz", 3))),
                               MSR = linebreak(c(rep("50 Hz", 2), 
                                                         rep("4 Hz", 3), 
                                                         rep("30 Hz", 3),
                                                         rep("1 Hz", 3), 
                                                         rep("10 Hz", 2), 
                                                         rep("1 Hz (HR)", 4), 
                                                         rep("4 Hz", 3), 
                                                         rep("1 Hz", 3))),
                               Features = linebreak(c("Mean", "Std Deviation", 
                                        "Mean" , "Std Deviation", "Max",
                                        "Mean", "Std Deviation", "Median", 
                                        "Mean", "Std Deviation", "Median", 
                                        "Mean",  "Std Deviation", 
                                        "Mean", "Std Deviation", "HR Mean", "HR Std Deviation",
                                        "Mean", "Std Deviation", "Max", 
                                        "Mean", "Std Deviation", "Median")))
kable(collapse_rows_dt, escape=F, booktabs = T, align = "llcc", caption = "Data Dictionary") %>%
  kable_styling(latex_options = c("hold_position")) %>% 
  group_rows(index = c("RespiBAN Chest Sensor" = 13, "Empatica E4 Wrist Sensor" = 10)) %>%
  column_spec(1, bold=T) %>%
  collapse_rows(columns = 1:3, latex_hline = "major", valign = "middle")
```

Note that while both sensors also included accelerometer data, it was not included in this analysis as it was only used to align the data points and distinguish the timestamps of the amusement and stress states. Other studies also have considered this variable and ultimately found it not to be useful, as you can read here [[9]][Bibliography].

For our final model, we decided to use linear interpolation to upsample the the electrocardiography *Empatica E4* data [[8]][Bibliography]. For example, say we observe the values $[2.0, 6.0, 12.0, 24.0]$ with 2 Hz as the current sampling rate (i.e. 2 and 6 are observations from the first second), and we wish to upsample to 4 Hz. We would translate these values to $[2.0, 3.33, 4.66, 6.0, 12.0, 16.0, 20.0, 24.0]$. We tested our model's sensitivity to this decison by also using forward projection (in the example above, forward projection would yield $[2.0, 2.0, 6.0, 6.0, 12.0, 12.0, 16.0, 16.0]$) and saw similar results, which is located in Table ** in the Appendix (REMOVE IF FALSE).

```{r Chest Model Sensitivity, echo=F}
wesad.2Hz <- read.csv("merged_wesad_data_2Hz.csv")
wesad.2Hz <- wesad.2Hz %>%
  mutate(label = as.factor(label),
         subject = as.factor(subject))
wesad.2Hz <- within(wesad.2Hz, subject <- relevel(subject, ref = "S2"))

model.chest.2Hz <- glm(label ~ EDA_CHEST_MEAN + Temp_CHEST_MEAN + subject, data = wesad.2Hz, family = binomial)
pander(model.chest.2Hz, caption = "Chest Model Output: 1 Minute Window, 0.5s Shift")

wesad.05Hz <- read.csv("merged_wesad_data_0_5Hz.csv")
wesad.05Hz <- wesad.05Hz %>%
  mutate(label = as.factor(label),
         subject = as.factor(subject))
wesad.05Hz <- within(wesad.05Hz, subject <- relevel(subject, ref = "S2"))

model.chest.05Hz <- glm(label ~ EDA_CHEST_MEAN + Temp_CHEST_MEAN + subject, data = wesad.05Hz, family = binomial)
pander(model.chest.05Hz, caption = "Chest Model Output: 2 Minute Window, 30s Shift")
```
 
For the chest model with a 1 minute window and 0.5 second shift, the estimates for the mean EDA and mean body temperature coefficients from the *RespiBAN* are nearly identical to our final model. Further, for the chest model with a 2 minute window and 30 second shift, the estimates for the same coefficients were within 2 standard errors of our final model.

```{r Wrist Model Sensitivity, echo=F}
model.wrist.2Hz <- glm(label ~ EDA_EMP4_STDDEV + TEMP_EMP4_MEAN + subject, data = wesad.2Hz, family = binomial)
pander(model.wrist.2Hz, caption = "Wrist Model Output: 1 Minute Window, 0.5s Shift")

model.wrist.05Hz <- glm(label ~ EDA_EMP4_STDDEV + TEMP_EMP4_MEAN + subject, data = wesad.05Hz, family = binomial)
pander(model.wrist.05Hz, caption = "Wrist Model Output: 2 Minute Window, 30s Shift")
```

For the wrist model with a 1 minute window and 0.5 second shift, the estimates for the mean EDA and mean body temperature coefficients from the *Empatica E4* are nearly identical to our final model. However, for the rist model with a 2 minute window and 30 second shift, the estimates for the mean EDA were not within 2 standard errors, and this model did regard mean skin temperature as significant. This may be due to the window size and shift being too large to capture critical changes.

```{r Wrist Temperature Model, warning=F, echo=F}
pander(final.model.interaction, caption="Wrist Model Output")
```

## Plots

### Distributions of EDA and Temperature Measured at Wrist

```{r fig.width=10, fig.height=4, fig.width = 11,message=F, echo=F}
# distribution of average body temperature measured at wrist (window = 60s, shift = 0.25s)
ggplot(wesad) +
  geom_histogram(aes(x=TEMP_EMP4_MEAN, fill=label),alpha = 0.6, position = "identity")+
  facet_wrap(~subject, nrow = 3, scales = "free")+
  labs(x = expression("Body Temperature " (degree*C)),
       title = "Empatica E4 Skin Temperature") 

# distribution of average electrodermal activity measured at wrist (window = 60s, shift = 0.25s)
ggplot(wesad) +
  geom_histogram(aes(x=EDA_EMP4_MEAN, fill=label),alpha = 0.6, position = "identity")+
  facet_wrap(~subject, nrow = 3, scales = "free")+
  labs(x = expression(paste("Electrodermal Activity (",mu,"S)")),
       title = "Empatica E4 Mean Electrodermal Activity")

# distribution of sd of electrodermal activity measured at wrist (window = 60s, shift = 0.25s)
ggplot(wesad) +
  geom_histogram(aes(x=EDA_EMP4_STDDEV, fill=label),alpha = 0.6, position = "identity")+
  facet_wrap(~subject, nrow = 3, scales = "free")+
  labs(x = expression(paste("Electrodermal Activity (",mu,"S)")),
       title = "Empatica E4 Standard Deviation of Electrodermal Activity")

```

### Chest Binned Residual Plots

```{r fig.width=6, fig.height=3, message=F, echo=F}
arm::binnedplot(x=model.chest.final$EDA_CHEST_MEAN,y=model.chest.final$.resid,
                xlab="RespiBAN Electrodermal Activity", 
                main = "Binned Residual vs. RespiBAN Electrodermal Activity",
                cex.main=0.9, cex.lab=0.8)
```

```{r fig.width=6, fig.height=3, message=F, echo=F}
arm::binnedplot(x=model.chest.final$Temp_CHEST_MEAN,y=model.chest.final$.resid,
                xlab="RespiBAN Body Temperature", 
                main = "Binned Residual vs. RespiBANBody Temperature",
                cex.main=0.9, cex.lab=0.8)
```

### Wrist Binned Residual Plots

```{r fig.width=6, fig.height=3, message=F, echo=F}
arm::binnedplot(x=model.wrist.final$EDA_EMP4_STDDEV,y=model.wrist.final$.resid,
                xlab="Standard Deviation of Electrodermal Activity", 
                main = "Binned Residual vs. EMP4 Electrodermal Activity")
```

```{r fig.width=6, fig.height=3, message=F, echo=F}
arm::binnedplot(x=model.wrist.final$TEMP_EMP4_MEAN,y=model.wrist.final$.resid,
                xlab="Mean Skin Temperature", 
                main = "Binned Residual vs. EMP4 Skin Temperature")
```

## Bibliography

1. Wray, S. (2017, July 27). Explosion of smart, wearable devices will triple revenue by 2016. Retrieved September 20, 2020, from https://inform.tmforum.org/features-and-analysis/2014/09/explosion-smart-wearable-devices-will-triple-revenue-2016/
2. Lu, T., Fu, C., Ma, M., Fang, C., & Turner, A. (2016, September 14). Healthcare Applications of Smart Watches. A Systematic Review. Retrieved September 20, 2020, from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5052554/
3. Hiner, J. (2020, April 27). How Apple Watch helped fix my toxic level of stress. Retrieved September 20, 2020, from https://www.cnet.com/news/apple-watch-uncovered-my-toxic-stress-level-and-helped-me-fix-it/
4. 5 Things You Should Know About Stress. (n.d.). Retrieved September 20, 2020, from https://www.nimh.nih.gov/health/publications/stress/index.shtml
5. Clark, E. (2019, October 17). New Report Finds That More Than Half of Wearable Users Fear Inaccurate Health Data, Malfunctions; Users Cautioned Against Relying on Devices. Retrieved September 20, 2020, from https://www.prnewswire.com/news-releases/new-report-finds-that-more-than-half-of-wearable-users-fear-inaccurate-health-data-malfunctions-users-cautioned-against-relying-on-devices-300940397.html
6. Weintraub, K. (2016, October 13). Wearable health monitors not always reliable, study shows. Retrieved September 20, 2020, from https://www.usatoday.com/story/news/2016/10/12/wearable-health-monitors-not-always-reliable-study-shows/91922858/
7. Philip Schmidt, Attila Reiss, Robert Duerichen, Claus Marberger, and Kristof Van Laerhoven. 2018. Introducing WESAD, a Multimodal Dataset for Wearable Stress and Affect Detection. In Proceedings of the 20th ACM International Conference on Multimodal Interaction (ICMI '18). Association for Computing Machinery, New York, NY, USA, 400???408. DOI:https://doi.org/10.1145/3242969.3242985
8. https://www.cs.toronto.edu/~guerzhoy/320/lec/upsampling.pdf
9. Gjoreski, M., Lutrek, M., Gams, M., &amp; Gjoreski, H. (2017, August 10). Monitoring stress with a wrist device using context. Retrieved September 27, 2020, from https://www.sciencedirect.com/science/article/pii/S1532046417301855
10. Mahdiani S, Jeyhani V, Peltokangas M, Vehkaoja A. Is 50 Hz high enough ECG sampling frequency for accurate HRV analysis? Annu Int Conf IEEE Eng Med Biol Soc. 2015;2015:5948-51. doi: 10.1109/EMBC.2015.7319746. PMID: 26737646.
11. Braithwaite, J. J., Watson, D. G., Jones, R., &amp; Rowe, M. (2013). A Guide for Analysing Electrodermal Activity (EDA) &amp; Skin Conductance Responses (SCRs) for Psychological Experiments. Retrieved September 26, 2020, from https://www.biopac.com/wp-content/uploads/EDA-SCR-Analysis.pdf
12. Pourmohammadi, S., &amp; Maleki, A. (2020, May 05). Stress detection using ECG and EMG signals: A comprehensive study. Retrieved September 27, 2020, from https://www.sciencedirect.com/science/article/pii/S0169260719320528
13. https://www.researchgate.net/post/Is_analysis_of_electrodermal_activity_data_possible_with_a_low_sampling_rate_of_only_2_Hz
